{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as albu\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from albumentations.pytorch.transforms import ToTensor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from Losses import ComboLoss, dice_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().__class_._name__\n",
    "    from tqdm.notebook import tqdm\n",
    "except:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count    = 612\n",
    "DATA_DIR       = Path(f'data/')\n",
    "TRAIN_IMG_DIR  = DATA_DIR/'images'\n",
    "TRAIN_MASK_DIR = DATA_DIR/'masks'\n",
    "RLE_DF_PATH    = 'rle.csv'\n",
    "KFOLD_PATH     = 'rle_kfold.csv'\n",
    "FOLD_ID        = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_binary(mask):\n",
    "    (threshold, black_and_white) = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    return black_and_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle(binary_mask):\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    counts = rle.get('counts')\n",
    "\n",
    "    last_elem = 0\n",
    "    running_length = 0\n",
    "\n",
    "    for i, elem in enumerate(binary_mask.ravel(order='F')):\n",
    "        if elem == last_elem:\n",
    "            pass\n",
    "        else:\n",
    "            counts.append(running_length)\n",
    "            running_length = 0\n",
    "            last_elem = elem\n",
    "        running_length += 1\n",
    "\n",
    "    counts.append(running_length)\n",
    "\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 612/612 [00:34<00:00, 17.88it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "image_ids = []\n",
    "encoded_pixels = []\n",
    "for file in tqdm(list(TRAIN_MASK_DIR.glob('**/*.tif'))):\n",
    "    img = cv2.imread(str(file), 0)\n",
    "    black_and_white = map_binary(img)\n",
    "    rle_encoded = rle(black_and_white)\n",
    "    image_ids.append(file.stem)\n",
    "    encoded_pixels.append(str(rle_encoded['counts'])[1:-1])\n",
    "\n",
    "data['ImageId'] = image_ids\n",
    "data['EncodedPixels'] = encoded_pixels\n",
    "rle_df = pd.DataFrame(data, columns=['ImageId', 'EncodedPixels'])\n",
    "rle_df.to_csv(RLE_DF_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ImageId                                      EncodedPixels\n",
      "0        1  11677, 54, 1, 8, 1, 14, 210, 53, 2, 8, 2, 1, 1...\n",
      "1       10  11575, 9, 10, 10, 258, 35, 252, 75, 212, 142, ...\n",
      "2      100  19728, 9, 274, 19, 263, 28, 256, 35, 251, 38, ...\n",
      "3      101  47679, 11, 274, 18, 268, 26, 260, 31, 255, 38,...\n",
      "4      102  47951, 24, 262, 27, 259, 32, 255, 35, 252, 37,...\n"
     ]
    }
   ],
   "source": [
    "RLE_DF = pd.read_csv(RLE_DF_PATH, names=['ImageId', 'EncodedPixels'], skiprows=1)\n",
    "print(RLE_DF.head())\n",
    "\n",
    "kf = StratifiedKFold()\n",
    "\n",
    "RLE_DF['has_mask'] = 0\n",
    "RLE_DF.loc[RLE_DF.EncodedPixels != '-1', 'has_mask'] = 1\n",
    "RLE_DF['kfold'] = -1\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X=RLE_DF.ImageId, y=RLE_DF.has_mask)):\n",
    "    RLE_DF.loc[test_index, 'kfold'] = fold\n",
    "    \n",
    "RLE_DF.to_csv(KFOLD_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(KFOLD_PATH)\n",
    "TRAIN_DF = DF.query(f'kfold!={FOLD_ID}').reset_index(drop=True)\n",
    "VAL_DF = DF.query(f'kfold=={FOLD_ID}').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, rle_df, image_base_dir, masks_base_dir, augmentation=None):\n",
    "        self.df             = rle_df\n",
    "        self.image_base_dir = image_base_dir\n",
    "        self.masks_base_dir = masks_base_dir\n",
    "        self.image_ids      = rle_df.ImageId.values\n",
    "        self.augmentation   = augmentation\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        image_id  = self.image_ids[i]\n",
    "        img_path  = os.path.join(self.image_base_dir, f'{image_id}.png')\n",
    "        mask_path = os.path.join(self.masks_base_dir, f'{image_id}.png')\n",
    "        image     = cv2.imread(img_path, 1)\n",
    "        mask      = cv2.imread(mask_path, 0)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = {'image': image, 'mask': mask}\n",
    "            sample = self.augmentation(**sample)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return {\n",
    "            'image': image,\n",
    "            'mask': mask\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformations = albu.Compose([\n",
    "    albu.HorizontalFlip(),\n",
    "    albu.Rotate(10),\n",
    "    albu.Normalize(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "test_transformations = albu.Compose([\n",
    "    albu.Normalize(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(TRAIN_DF, TRAIN_IMG_DIR, TRAIN_MASK_DIR, train_transformations)\n",
    "test_dataset = Dataset(VAL_DF, TRAIN_IMG_DIR, TRAIN_MASK_DIR, test_transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
